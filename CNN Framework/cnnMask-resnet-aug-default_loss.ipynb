{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Implementation (Method 1)\n",
    "Model is constructed with multiple outs, calculated loss between outputs is independent from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random, json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import time\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_sample_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging stuff\n",
    "model_name  = \"cnnMask_resnet_multiout_default_loss_{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(face_with_mask              2034\n",
       " face_no_mask                 773\n",
       " face_other_covering          675\n",
       " face_with_mask_incorrect      68\n",
       " Name: classname, dtype: int64,\n",
       " face_with_mask              881\n",
       " face_no_mask                325\n",
       " face_other_covering         284\n",
       " face_with_mask_incorrect     32\n",
       " Name: classname, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "NUM_EPOCHS = 15\n",
    "IMG_SIZE   = (128, 128)\n",
    "\n",
    "percent_val = 0.1\n",
    "\n",
    "mask_train = pd.read_csv('../FINAL_DATASET/traindf.csv')\n",
    "mask_test  = pd.read_csv('../FINAL_DATASET/test.csv')\n",
    "\n",
    "mask_train['classname'].value_counts(), mask_test['classname'].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "face_no_mask                2915\n",
       "face_with_mask_incorrect    2915\n",
       "face_with_mask              2915\n",
       "face_other_covering         2915\n",
       "Name: classname, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_classes = pd.concat([mask_train, mask_test]).groupby('classname')\\\n",
    "# Uncomment to make number of images from each class equal\n",
    "# num_per_class = equal_classes.size().max() # or equal_classes.size().max(), equal_classes.size().min()\n",
    "# equal_classes = pd.DataFrame(equal_classes.apply(lambda x : x.sample(num_per_class, replace = True)).reset_index(drop = True))\n",
    "equal_classes = equal_classes.sample(frac = 1)\n",
    "\n",
    "equal_classes['classname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type  usage\n",
       " 0.0   0.0      5247\n",
       " 1.0   1.0      2624\n",
       "       0.0      2623\n",
       " dtype: int64,\n",
       " type  usage\n",
       " 0.0   0.0      583\n",
       " 1.0   0.0      292\n",
       "       1.0      291\n",
       " dtype: int64,\n",
       " type  usage\n",
       " 1.0   0.0      292\n",
       "       1.0      291\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_classes['type' ] = equal_classes['classname']\n",
    "equal_classes['usage'] = equal_classes['classname']\n",
    "\n",
    "replacement_dict = {\n",
    "    'type': { \n",
    "        'face_other_covering'       : 0.0,\n",
    "        'face_with_mask_incorrect'  : 1.0,\n",
    "        'face_with_mask'            : 1.0,\n",
    "        'face_no_mask'              : 0.0,\n",
    "    },  \n",
    "    'usage': { \n",
    "        'face_other_covering'       : 0.0,\n",
    "        'face_with_mask_incorrect'  : 0.0,\n",
    "        'face_with_mask'            : 1.0,\n",
    "        'face_no_mask'              : 0.0,\n",
    "    }\n",
    "}\n",
    "\n",
    "equal_classes = equal_classes.replace(replacement_dict)\n",
    "equal_classes[['type', 'usage']].value_counts()\n",
    "\n",
    "mask_train, mask_test = train_test_split(equal_classes, test_size = percent_val, stratify = equal_classes[['type', 'usage']])\n",
    "valid_mask_test       = mask_test[mask_test['type'] != 0.0]\n",
    "\n",
    "(mask_train[['type', 'usage']].value_counts(), mask_test[['type', 'usage']].value_counts(), valid_mask_test[['type', 'usage']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image(input_image):\n",
    "    brightness = random.choice([1.0, 0.8, 1.2])\n",
    "    contrast   = random.choice([1.0, 0.8, 1.2])\n",
    "    saturation = random.choice([1.0, 0.8, 1.2])\n",
    "\n",
    "    img_proc = cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)\n",
    "    np.multiply(img_proc, np.array([ 1.0, saturation, 1.0 ], dtype = np.single), out = img_proc)\n",
    "    \n",
    "    img_proc[img_proc > 255] = 255\n",
    "    img_proc[img_proc < 0]   = 0\n",
    "\n",
    "    cv2.cvtColor(img_proc, cv2.COLOR_HSV2RGB, dst = img_proc)\n",
    "    np.multiply(img_proc, brightness, out = img_proc)\n",
    "    np.add(img_proc, ((1-contrast) * 100))\n",
    "\n",
    "    img_proc[img_proc > 255] = 255\n",
    "    img_proc[img_proc < 0]   = 0\n",
    "    img_proc  = img_proc.astype(np.float32) * (1.0 / 255)\n",
    "\n",
    "    return img_proc\n",
    "\n",
    "image_gen  = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range      = 0.1, \n",
    "                                                             height_shift_range     = 0.1, \n",
    "                                                             horizontal_flip        = True,\n",
    "                                                             preprocessing_function = adjust_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10494 validated image filenames.\n",
      "Found 1166 validated image filenames.\n",
      "Found 583 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_gen.flow_from_dataframe(mask_train, '../FINAL_DATASET/croppedv2', \n",
    "                                              x_col       = 'newFilename', \n",
    "                                              y_col       = ['type', 'usage'], \n",
    "                                              target_size = IMG_SIZE, \n",
    "                                              class_mode  = 'multi_output',\n",
    "                                              subset      = \"training\", \n",
    "                                              batch_size  = BATCH_SIZE)\n",
    "\n",
    "test_ds = image_gen.flow_from_dataframe(mask_test, '../FINAL_DATASET/croppedv2', \n",
    "                                            x_col       = 'newFilename', \n",
    "                                            y_col       = ['type', 'usage'], \n",
    "                                            target_size = IMG_SIZE, \n",
    "                                            class_mode  = 'multi_output',\n",
    "                                            batch_size  = BATCH_SIZE)\n",
    "\n",
    "valid_mask_test_ds = image_gen.flow_from_dataframe(valid_mask_test, '../FINAL_DATASET/croppedv2', \n",
    "                                            x_col       = 'newFilename', \n",
    "                                            y_col       = ['type', 'usage'], \n",
    "                                            target_size = IMG_SIZE, \n",
    "                                            class_mode  = 'multi_output',\n",
    "                                            batch_size  = BATCH_SIZE)                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage and Type classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resnet50 (Functional)          (None, 2048)         23587712    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['resnet50[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          524544      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mask_type (Dense)              (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " mask_usage (Dense)             (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,112,770\n",
      "Trainable params: 24,059,650\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img  = tf.keras.layers.Input(shape = (128, 128, 3))\n",
    "\n",
    "def build_cnn_model():\n",
    "    base = tf.keras.applications.ResNet50(include_top = False, input_shape = (*IMG_SIZE,3), pooling = 'max')(input_img)\n",
    "    base = tf.keras.layers.Flatten()(base)\n",
    "    base = tf.keras.layers.Dense(256, activation = 'relu')(base)\n",
    "    \n",
    "    type_out = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'mask_type')(base)\n",
    "\n",
    "    usage_out = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'mask_usage')(base)\n",
    "\n",
    "    model = tf.keras.Model(inputs = input_img, outputs = [type_out, usage_out])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "              loss      = [tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.BinaryCrossentropy()], \n",
    "              metrics   = [ \n",
    "                    'accuracy', \n",
    "                    tf.keras.metrics.Precision(), \n",
    "                    tf.keras.metrics.Recall(),\n",
    "                    tf.keras.metrics.TruePositives(),\n",
    "                    tf.keras.metrics.FalsePositives(),\n",
    "                    tf.keras.metrics.TrueNegatives(),\n",
    "                    tf.keras.metrics.FalseNegatives(),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2099/2099 [==============================] - 174s 78ms/step - loss: 1.0997 - mask_type_loss: 0.5499 - mask_usage_loss: 0.5498 - mask_type_accuracy: 0.7732 - mask_type_precision: 0.7715 - mask_type_recall: 0.7763 - mask_type_true_positives: 4073.0000 - mask_type_false_positives: 1206.0000 - mask_type_true_negatives: 4041.0000 - mask_type_false_negatives: 1174.0000 - mask_usage_accuracy: 0.7676 - mask_usage_precision: 0.5569 - mask_usage_recall: 0.3453 - mask_usage_true_positives: 906.0000 - mask_usage_false_positives: 721.0000 - mask_usage_true_negatives: 7149.0000 - mask_usage_false_negatives: 1718.0000 - val_loss: 3.7003 - val_mask_type_loss: 2.4918 - val_mask_usage_loss: 1.2085 - val_mask_type_accuracy: 0.5583 - val_mask_type_precision: 0.5311 - val_mask_type_recall: 0.9949 - val_mask_type_true_positives: 580.0000 - val_mask_type_false_positives: 512.0000 - val_mask_type_true_negatives: 71.0000 - val_mask_type_false_negatives: 3.0000 - val_mask_usage_accuracy: 0.3722 - val_mask_usage_precision: 0.2828 - val_mask_usage_recall: 0.9863 - val_mask_usage_true_positives: 287.0000 - val_mask_usage_false_positives: 728.0000 - val_mask_usage_true_negatives: 147.0000 - val_mask_usage_false_negatives: 4.0000\n",
      "Epoch 2/15\n",
      "2099/2099 [==============================] - 163s 77ms/step - loss: 0.8629 - mask_type_loss: 0.4206 - mask_usage_loss: 0.4423 - mask_type_accuracy: 0.8134 - mask_type_precision: 0.8186 - mask_type_recall: 0.8052 - mask_type_true_positives: 4225.0000 - mask_type_false_positives: 936.0000 - mask_type_true_negatives: 4311.0000 - mask_type_false_negatives: 1022.0000 - mask_usage_accuracy: 0.7928 - mask_usage_precision: 0.6311 - mask_usage_recall: 0.4127 - mask_usage_true_positives: 1083.0000 - mask_usage_false_positives: 633.0000 - mask_usage_true_negatives: 7237.0000 - mask_usage_false_negatives: 1541.0000 - val_loss: 0.8969 - val_mask_type_loss: 0.4667 - val_mask_usage_loss: 0.4302 - val_mask_type_accuracy: 0.7813 - val_mask_type_precision: 0.7993 - val_mask_type_recall: 0.7513 - val_mask_type_true_positives: 438.0000 - val_mask_type_false_positives: 110.0000 - val_mask_type_true_negatives: 473.0000 - val_mask_type_false_negatives: 145.0000 - val_mask_usage_accuracy: 0.7856 - val_mask_usage_precision: 0.6041 - val_mask_usage_recall: 0.4089 - val_mask_usage_true_positives: 119.0000 - val_mask_usage_false_positives: 78.0000 - val_mask_usage_true_negatives: 797.0000 - val_mask_usage_false_negatives: 172.0000\n",
      "Epoch 3/15\n",
      "2099/2099 [==============================] - 159s 76ms/step - loss: 0.7611 - mask_type_loss: 0.3765 - mask_usage_loss: 0.3846 - mask_type_accuracy: 0.8379 - mask_type_precision: 0.8457 - mask_type_recall: 0.8266 - mask_type_true_positives: 4337.0000 - mask_type_false_positives: 791.0000 - mask_type_true_negatives: 4456.0000 - mask_type_false_negatives: 910.0000 - mask_usage_accuracy: 0.8258 - mask_usage_precision: 0.7026 - mask_usage_recall: 0.5259 - mask_usage_true_positives: 1380.0000 - mask_usage_false_positives: 584.0000 - mask_usage_true_negatives: 7286.0000 - mask_usage_false_negatives: 1244.0000 - val_loss: 0.7500 - val_mask_type_loss: 0.3392 - val_mask_usage_loss: 0.4108 - val_mask_type_accuracy: 0.8628 - val_mask_type_precision: 0.8384 - val_mask_type_recall: 0.8988 - val_mask_type_true_positives: 524.0000 - val_mask_type_false_positives: 101.0000 - val_mask_type_true_negatives: 482.0000 - val_mask_type_false_negatives: 59.0000 - val_mask_usage_accuracy: 0.8250 - val_mask_usage_precision: 0.8042 - val_mask_usage_recall: 0.3952 - val_mask_usage_true_positives: 115.0000 - val_mask_usage_false_positives: 28.0000 - val_mask_usage_true_negatives: 847.0000 - val_mask_usage_false_negatives: 176.0000\n",
      "Epoch 4/15\n",
      "2099/2099 [==============================] - 157s 75ms/step - loss: 0.6959 - mask_type_loss: 0.3443 - mask_usage_loss: 0.3516 - mask_type_accuracy: 0.8502 - mask_type_precision: 0.8439 - mask_type_recall: 0.8593 - mask_type_true_positives: 4509.0000 - mask_type_false_positives: 834.0000 - mask_type_true_negatives: 4413.0000 - mask_type_false_negatives: 738.0000 - mask_usage_accuracy: 0.8470 - mask_usage_precision: 0.7637 - mask_usage_recall: 0.5617 - mask_usage_true_positives: 1474.0000 - mask_usage_false_positives: 456.0000 - mask_usage_true_negatives: 7414.0000 - mask_usage_false_negatives: 1150.0000 - val_loss: 0.6382 - val_mask_type_loss: 0.3466 - val_mask_usage_loss: 0.2916 - val_mask_type_accuracy: 0.8379 - val_mask_type_precision: 0.8316 - val_mask_type_recall: 0.8473 - val_mask_type_true_positives: 494.0000 - val_mask_type_false_positives: 100.0000 - val_mask_type_true_negatives: 483.0000 - val_mask_type_false_negatives: 89.0000 - val_mask_usage_accuracy: 0.8868 - val_mask_usage_precision: 0.8768 - val_mask_usage_recall: 0.6357 - val_mask_usage_true_positives: 185.0000 - val_mask_usage_false_positives: 26.0000 - val_mask_usage_true_negatives: 849.0000 - val_mask_usage_false_negatives: 106.0000\n",
      "Epoch 5/15\n",
      "2099/2099 [==============================] - 230s 110ms/step - loss: 0.6408 - mask_type_loss: 0.3179 - mask_usage_loss: 0.3228 - mask_type_accuracy: 0.8623 - mask_type_precision: 0.8590 - mask_type_recall: 0.8670 - mask_type_true_positives: 4549.0000 - mask_type_false_positives: 747.0000 - mask_type_true_negatives: 4500.0000 - mask_type_false_negatives: 698.0000 - mask_usage_accuracy: 0.8612 - mask_usage_precision: 0.7859 - mask_usage_recall: 0.6113 - mask_usage_true_positives: 1604.0000 - mask_usage_false_positives: 437.0000 - mask_usage_true_negatives: 7433.0000 - mask_usage_false_negatives: 1020.0000 - val_loss: 0.5845 - val_mask_type_loss: 0.2859 - val_mask_usage_loss: 0.2985 - val_mask_type_accuracy: 0.8568 - val_mask_type_precision: 0.8114 - val_mask_type_recall: 0.9297 - val_mask_type_true_positives: 542.0000 - val_mask_type_false_positives: 126.0000 - val_mask_type_true_negatives: 457.0000 - val_mask_type_false_negatives: 41.0000 - val_mask_usage_accuracy: 0.8688 - val_mask_usage_precision: 0.7212 - val_mask_usage_recall: 0.7732 - val_mask_usage_true_positives: 225.0000 - val_mask_usage_false_positives: 87.0000 - val_mask_usage_true_negatives: 788.0000 - val_mask_usage_false_negatives: 66.0000\n",
      "Epoch 6/15\n",
      "2099/2099 [==============================] - 394s 187ms/step - loss: 0.5645 - mask_type_loss: 0.2765 - mask_usage_loss: 0.2881 - mask_type_accuracy: 0.8817 - mask_type_precision: 0.8747 - mask_type_recall: 0.8912 - mask_type_true_positives: 4676.0000 - mask_type_false_positives: 670.0000 - mask_type_true_negatives: 4577.0000 - mask_type_false_negatives: 571.0000 - mask_usage_accuracy: 0.8776 - mask_usage_precision: 0.7913 - mask_usage_recall: 0.6936 - mask_usage_true_positives: 1820.0000 - mask_usage_false_positives: 480.0000 - mask_usage_true_negatives: 7390.0000 - mask_usage_false_negatives: 804.0000 - val_loss: 0.5450 - val_mask_type_loss: 0.2521 - val_mask_usage_loss: 0.2929 - val_mask_type_accuracy: 0.8851 - val_mask_type_precision: 0.9060 - val_mask_type_recall: 0.8593 - val_mask_type_true_positives: 501.0000 - val_mask_type_false_positives: 52.0000 - val_mask_type_true_negatives: 531.0000 - val_mask_type_false_negatives: 82.0000 - val_mask_usage_accuracy: 0.8705 - val_mask_usage_precision: 0.7632 - val_mask_usage_recall: 0.6976 - val_mask_usage_true_positives: 203.0000 - val_mask_usage_false_positives: 63.0000 - val_mask_usage_true_negatives: 812.0000 - val_mask_usage_false_negatives: 88.0000\n",
      "Epoch 7/15\n",
      "2099/2099 [==============================] - 443s 211ms/step - loss: 0.5169 - mask_type_loss: 0.2486 - mask_usage_loss: 0.2683 - mask_type_accuracy: 0.8941 - mask_type_precision: 0.8950 - mask_type_recall: 0.8931 - mask_type_true_positives: 4686.0000 - mask_type_false_positives: 550.0000 - mask_type_true_negatives: 4697.0000 - mask_type_false_negatives: 561.0000 - mask_usage_accuracy: 0.8871 - mask_usage_precision: 0.8208 - mask_usage_recall: 0.7016 - mask_usage_true_positives: 1841.0000 - mask_usage_false_positives: 402.0000 - mask_usage_true_negatives: 7468.0000 - mask_usage_false_negatives: 783.0000 - val_loss: 0.6495 - val_mask_type_loss: 0.3599 - val_mask_usage_loss: 0.2897 - val_mask_type_accuracy: 0.8208 - val_mask_type_precision: 0.9583 - val_mask_type_recall: 0.6707 - val_mask_type_true_positives: 391.0000 - val_mask_type_false_positives: 17.0000 - val_mask_type_true_negatives: 566.0000 - val_mask_type_false_negatives: 192.0000 - val_mask_usage_accuracy: 0.8877 - val_mask_usage_precision: 0.8883 - val_mask_usage_recall: 0.6289 - val_mask_usage_true_positives: 183.0000 - val_mask_usage_false_positives: 23.0000 - val_mask_usage_true_negatives: 852.0000 - val_mask_usage_false_negatives: 108.0000\n",
      "Epoch 8/15\n",
      "2099/2099 [==============================] - 448s 213ms/step - loss: 0.4778 - mask_type_loss: 0.2316 - mask_usage_loss: 0.2462 - mask_type_accuracy: 0.9014 - mask_type_precision: 0.9139 - mask_type_recall: 0.8862 - mask_type_true_positives: 4650.0000 - mask_type_false_positives: 438.0000 - mask_type_true_negatives: 4809.0000 - mask_type_false_negatives: 597.0000 - mask_usage_accuracy: 0.8962 - mask_usage_precision: 0.8422 - mask_usage_recall: 0.7199 - mask_usage_true_positives: 1889.0000 - mask_usage_false_positives: 354.0000 - mask_usage_true_negatives: 7516.0000 - mask_usage_false_negatives: 735.0000 - val_loss: 0.5627 - val_mask_type_loss: 0.2662 - val_mask_usage_loss: 0.2965 - val_mask_type_accuracy: 0.8782 - val_mask_type_precision: 0.8959 - val_mask_type_recall: 0.8559 - val_mask_type_true_positives: 499.0000 - val_mask_type_false_positives: 58.0000 - val_mask_type_true_negatives: 525.0000 - val_mask_type_false_negatives: 84.0000 - val_mask_usage_accuracy: 0.8662 - val_mask_usage_precision: 0.8689 - val_mask_usage_recall: 0.5464 - val_mask_usage_true_positives: 159.0000 - val_mask_usage_false_positives: 24.0000 - val_mask_usage_true_negatives: 851.0000 - val_mask_usage_false_negatives: 132.0000\n",
      "Epoch 9/15\n",
      "2099/2099 [==============================] - 401s 191ms/step - loss: 0.4360 - mask_type_loss: 0.2152 - mask_usage_loss: 0.2207 - mask_type_accuracy: 0.9112 - mask_type_precision: 0.9197 - mask_type_recall: 0.9011 - mask_type_true_positives: 4728.0000 - mask_type_false_positives: 413.0000 - mask_type_true_negatives: 4834.0000 - mask_type_false_negatives: 519.0000 - mask_usage_accuracy: 0.9090 - mask_usage_precision: 0.8595 - mask_usage_recall: 0.7603 - mask_usage_true_positives: 1995.0000 - mask_usage_false_positives: 326.0000 - mask_usage_true_negatives: 7544.0000 - mask_usage_false_negatives: 629.0000 - val_loss: 0.7274 - val_mask_type_loss: 0.4195 - val_mask_usage_loss: 0.3079 - val_mask_type_accuracy: 0.8456 - val_mask_type_precision: 0.7834 - val_mask_type_recall: 0.9554 - val_mask_type_true_positives: 557.0000 - val_mask_type_false_positives: 154.0000 - val_mask_type_true_negatives: 429.0000 - val_mask_type_false_negatives: 26.0000 - val_mask_usage_accuracy: 0.8799 - val_mask_usage_precision: 0.7151 - val_mask_usage_recall: 0.8625 - val_mask_usage_true_positives: 251.0000 - val_mask_usage_false_positives: 100.0000 - val_mask_usage_true_negatives: 775.0000 - val_mask_usage_false_negatives: 40.0000\n",
      "Epoch 10/15\n",
      "2099/2099 [==============================] - 407s 194ms/step - loss: 0.4038 - mask_type_loss: 0.1924 - mask_usage_loss: 0.2114 - mask_type_accuracy: 0.9205 - mask_type_precision: 0.9249 - mask_type_recall: 0.9154 - mask_type_true_positives: 4803.0000 - mask_type_false_positives: 390.0000 - mask_type_true_negatives: 4857.0000 - mask_type_false_negatives: 444.0000 - mask_usage_accuracy: 0.9158 - mask_usage_precision: 0.8686 - mask_usage_recall: 0.7812 - mask_usage_true_positives: 2050.0000 - mask_usage_false_positives: 310.0000 - mask_usage_true_negatives: 7560.0000 - mask_usage_false_negatives: 574.0000 - val_loss: 0.4306 - val_mask_type_loss: 0.1988 - val_mask_usage_loss: 0.2318 - val_mask_type_accuracy: 0.9237 - val_mask_type_precision: 0.9442 - val_mask_type_recall: 0.9005 - val_mask_type_true_positives: 525.0000 - val_mask_type_false_positives: 31.0000 - val_mask_type_true_negatives: 552.0000 - val_mask_type_false_negatives: 58.0000 - val_mask_usage_accuracy: 0.9039 - val_mask_usage_precision: 0.8163 - val_mask_usage_recall: 0.7938 - val_mask_usage_true_positives: 231.0000 - val_mask_usage_false_positives: 52.0000 - val_mask_usage_true_negatives: 823.0000 - val_mask_usage_false_negatives: 60.0000\n",
      "Epoch 11/15\n",
      "2099/2099 [==============================] - 406s 193ms/step - loss: 0.3885 - mask_type_loss: 0.1828 - mask_usage_loss: 0.2058 - mask_type_accuracy: 0.9255 - mask_type_precision: 0.9336 - mask_type_recall: 0.9161 - mask_type_true_positives: 4807.0000 - mask_type_false_positives: 342.0000 - mask_type_true_negatives: 4905.0000 - mask_type_false_negatives: 440.0000 - mask_usage_accuracy: 0.9167 - mask_usage_precision: 0.8704 - mask_usage_recall: 0.7835 - mask_usage_true_positives: 2056.0000 - mask_usage_false_positives: 306.0000 - mask_usage_true_negatives: 7564.0000 - mask_usage_false_negatives: 568.0000 - val_loss: 0.5776 - val_mask_type_loss: 0.3056 - val_mask_usage_loss: 0.2720 - val_mask_type_accuracy: 0.8585 - val_mask_type_precision: 0.9604 - val_mask_type_recall: 0.7479 - val_mask_type_true_positives: 436.0000 - val_mask_type_false_positives: 18.0000 - val_mask_type_true_negatives: 565.0000 - val_mask_type_false_negatives: 147.0000 - val_mask_usage_accuracy: 0.8834 - val_mask_usage_precision: 0.7992 - val_mask_usage_recall: 0.7113 - val_mask_usage_true_positives: 207.0000 - val_mask_usage_false_positives: 52.0000 - val_mask_usage_true_negatives: 823.0000 - val_mask_usage_false_negatives: 84.0000\n",
      "Epoch 12/15\n",
      "2099/2099 [==============================] - 404s 193ms/step - loss: 0.3618 - mask_type_loss: 0.1763 - mask_usage_loss: 0.1855 - mask_type_accuracy: 0.9282 - mask_type_precision: 0.9350 - mask_type_recall: 0.9205 - mask_type_true_positives: 4830.0000 - mask_type_false_positives: 336.0000 - mask_type_true_negatives: 4911.0000 - mask_type_false_negatives: 417.0000 - mask_usage_accuracy: 0.9259 - mask_usage_precision: 0.8924 - mask_usage_recall: 0.7999 - mask_usage_true_positives: 2099.0000 - mask_usage_false_positives: 253.0000 - mask_usage_true_negatives: 7617.0000 - mask_usage_false_negatives: 525.0000 - val_loss: 0.3119 - val_mask_type_loss: 0.1548 - val_mask_usage_loss: 0.1571 - val_mask_type_accuracy: 0.9340 - val_mask_type_precision: 0.9439 - val_mask_type_recall: 0.9228 - val_mask_type_true_positives: 538.0000 - val_mask_type_false_positives: 32.0000 - val_mask_type_true_negatives: 551.0000 - val_mask_type_false_negatives: 45.0000 - val_mask_usage_accuracy: 0.9400 - val_mask_usage_precision: 0.9202 - val_mask_usage_recall: 0.8316 - val_mask_usage_true_positives: 242.0000 - val_mask_usage_false_positives: 21.0000 - val_mask_usage_true_negatives: 854.0000 - val_mask_usage_false_negatives: 49.0000\n",
      "Epoch 13/15\n",
      "2099/2099 [==============================] - 387s 184ms/step - loss: 0.3413 - mask_type_loss: 0.1647 - mask_usage_loss: 0.1766 - mask_type_accuracy: 0.9322 - mask_type_precision: 0.9397 - mask_type_recall: 0.9236 - mask_type_true_positives: 4846.0000 - mask_type_false_positives: 311.0000 - mask_type_true_negatives: 4936.0000 - mask_type_false_negatives: 401.0000 - mask_usage_accuracy: 0.9268 - mask_usage_precision: 0.8883 - mask_usage_recall: 0.8091 - mask_usage_true_positives: 2123.0000 - mask_usage_false_positives: 267.0000 - mask_usage_true_negatives: 7603.0000 - mask_usage_false_negatives: 501.0000 - val_loss: 0.9679 - val_mask_type_loss: 0.5707 - val_mask_usage_loss: 0.3972 - val_mask_type_accuracy: 0.8310 - val_mask_type_precision: 0.9825 - val_mask_type_recall: 0.6741 - val_mask_type_true_positives: 393.0000 - val_mask_type_false_positives: 7.0000 - val_mask_type_true_negatives: 576.0000 - val_mask_type_false_negatives: 190.0000 - val_mask_usage_accuracy: 0.8731 - val_mask_usage_precision: 0.9231 - val_mask_usage_recall: 0.5361 - val_mask_usage_true_positives: 156.0000 - val_mask_usage_false_positives: 13.0000 - val_mask_usage_true_negatives: 862.0000 - val_mask_usage_false_negatives: 135.0000\n",
      "Epoch 14/15\n",
      "2099/2099 [==============================] - 402s 191ms/step - loss: 0.3188 - mask_type_loss: 0.1554 - mask_usage_loss: 0.1634 - mask_type_accuracy: 0.9355 - mask_type_precision: 0.9451 - mask_type_recall: 0.9247 - mask_type_true_positives: 4852.0000 - mask_type_false_positives: 282.0000 - mask_type_true_negatives: 4965.0000 - mask_type_false_negatives: 395.0000 - mask_usage_accuracy: 0.9345 - mask_usage_precision: 0.9014 - mask_usage_recall: 0.8289 - mask_usage_true_positives: 2175.0000 - mask_usage_false_positives: 238.0000 - mask_usage_true_negatives: 7632.0000 - mask_usage_false_negatives: 449.0000 - val_loss: 0.3606 - val_mask_type_loss: 0.1639 - val_mask_usage_loss: 0.1968 - val_mask_type_accuracy: 0.9280 - val_mask_type_precision: 0.9432 - val_mask_type_recall: 0.9108 - val_mask_type_true_positives: 531.0000 - val_mask_type_false_positives: 32.0000 - val_mask_type_true_negatives: 551.0000 - val_mask_type_false_negatives: 52.0000 - val_mask_usage_accuracy: 0.9185 - val_mask_usage_precision: 0.8333 - val_mask_usage_recall: 0.8419 - val_mask_usage_true_positives: 245.0000 - val_mask_usage_false_positives: 49.0000 - val_mask_usage_true_negatives: 826.0000 - val_mask_usage_false_negatives: 46.0000\n",
      "Epoch 15/15\n",
      "2099/2099 [==============================] - 402s 192ms/step - loss: 0.2914 - mask_type_loss: 0.1374 - mask_usage_loss: 0.1540 - mask_type_accuracy: 0.9457 - mask_type_precision: 0.9512 - mask_type_recall: 0.9396 - mask_type_true_positives: 4930.0000 - mask_type_false_positives: 253.0000 - mask_type_true_negatives: 4994.0000 - mask_type_false_negatives: 317.0000 - mask_usage_accuracy: 0.9401 - mask_usage_precision: 0.9050 - mask_usage_recall: 0.8495 - mask_usage_true_positives: 2229.0000 - mask_usage_false_positives: 234.0000 - mask_usage_true_negatives: 7636.0000 - mask_usage_false_negatives: 395.0000 - val_loss: 0.6089 - val_mask_type_loss: 0.3453 - val_mask_usage_loss: 0.2636 - val_mask_type_accuracy: 0.8431 - val_mask_type_precision: 0.9762 - val_mask_type_recall: 0.7033 - val_mask_type_true_positives: 410.0000 - val_mask_type_false_positives: 10.0000 - val_mask_type_true_negatives: 573.0000 - val_mask_type_false_negatives: 173.0000 - val_mask_usage_accuracy: 0.8816 - val_mask_usage_precision: 0.8370 - val_mask_usage_recall: 0.6529 - val_mask_usage_true_positives: 190.0000 - val_mask_usage_false_positives: 37.0000 - val_mask_usage_true_negatives: 838.0000 - val_mask_usage_false_negatives: 101.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = test_ds, epochs = NUM_EPOCHS, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 22s 92ms/step - loss: 0.6506 - mask_type_loss: 0.3859 - mask_usage_loss: 0.2646 - mask_type_accuracy: 0.8370 - mask_type_precision: 0.9712 - mask_type_recall: 0.6947 - mask_type_true_positives: 405.0000 - mask_type_false_positives: 12.0000 - mask_type_true_negatives: 571.0000 - mask_type_false_negatives: 178.0000 - mask_usage_accuracy: 0.8868 - mask_usage_precision: 0.8502 - mask_usage_recall: 0.6632 - mask_usage_true_positives: 193.0000 - mask_usage_false_positives: 34.0000 - mask_usage_true_negatives: 841.0000 - mask_usage_false_negatives: 98.0000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_ds, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 12s 99ms/step - loss: 1.0527 - mask_type_loss: 0.6181 - mask_usage_loss: 0.4346 - mask_type_accuracy: 0.7084 - mask_type_precision: 1.0000 - mask_type_recall: 0.7084 - mask_type_true_positives: 413.0000 - mask_type_false_positives: 0.0000e+00 - mask_type_true_negatives: 0.0000e+00 - mask_type_false_negatives: 170.0000 - mask_usage_accuracy: 0.8148 - mask_usage_precision: 0.9067 - mask_usage_recall: 0.7010 - mask_usage_true_positives: 204.0000 - mask_usage_false_positives: 21.0000 - mask_usage_true_negatives: 271.0000 - mask_usage_false_negatives: 87.0000\n"
     ]
    }
   ],
   "source": [
    "results_for_valid_masks = model.evaluate(valid_mask_test_ds, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved-models/cnnMask_resnet_multiout_default_loss_1650938061\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved-models/{}'.format(model_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27b062b3dfe9606f0c2128da30d74d9d8143ed6a1aa3be014384e6a51e358474"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
