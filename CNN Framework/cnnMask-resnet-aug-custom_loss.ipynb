{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Implementation (Method 2)\n",
    "Model is constructed with multiple outputs, calculated type loss remains the same, \n",
    "usage loss is mutiplied with y_type ground truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import random, json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import time\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_sample_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging stuff\n",
    "model_name  = \"cnnMask_resnet_multiout_custom_loss_{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "NUM_EPOCHS = 15\n",
    "IMG_SIZE   = (128, 128)\n",
    "\n",
    "DATASET_DIR = '../FINAL_DATASET'\n",
    "IMAGE_DIR   = DATASET_DIR + '/croppedv2/'\n",
    "\n",
    "percent_val = 0.1\n",
    "\n",
    "mask_train = pd.read_csv(DATASET_DIR + '/traindf.csv')\n",
    "mask_test  = pd.read_csv(DATASET_DIR + '/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample all classes so that the number of images from each class are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_classes = pd.concat([mask_train, mask_test]).groupby('classname')\n",
    "# Uncomment to sample all classes to make them equal sizes\n",
    "#num_per_class = equal_classes.size().max() # or equal_classes.size().max(), equal_classes.size().min()\n",
    "#equal_classes = pd.DataFrame(equal_classes.apply(lambda x : x.sample(num_per_class, replace = True)).reset_index(drop = True))\n",
    "equal_classes = equal_classes.sample(frac = 1)\n",
    "\n",
    "equal_classes['classname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_classes['type' ] = equal_classes['classname']\n",
    "equal_classes['usage'] = equal_classes['classname']\n",
    "\n",
    "replacement_dict = {\n",
    "    'type': { \n",
    "        'face_other_covering'       : 0.0,\n",
    "        'face_with_mask_incorrect'  : 1.0,\n",
    "        'face_with_mask'            : 1.0,\n",
    "        'face_no_mask'              : 0.0,\n",
    "    },  \n",
    "    'usage': { \n",
    "        'face_other_covering'       :-1.0,\n",
    "        'face_with_mask_incorrect'  : 0.0,\n",
    "        'face_with_mask'            : 1.0,\n",
    "        'face_no_mask'              :-1.0,\n",
    "    }\n",
    "}\n",
    "\n",
    "equal_classes = equal_classes.replace(replacement_dict)\n",
    "equal_classes[['type', 'usage']].value_counts()\n",
    "\n",
    "mask_train, mask_test = train_test_split(equal_classes, test_size = percent_val, stratify = equal_classes[['type', 'usage']])\n",
    "valid_mask_test       = mask_test[mask_test['usage'] != -1.0]\n",
    "#, mask_test[['type', 'usage']].value_counts() / valid_mask_test[['type', 'usage']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask_train[['type', 'usage']].value_counts())\n",
    "print(mask_test[['type', 'usage']].value_counts())\n",
    "print(valid_mask_test[['type', 'usage']].value_counts())\n",
    "print()\n",
    "\n",
    "print(mask_train[['type', 'usage']].value_counts() / len(mask_train))\n",
    "print(mask_test[['type', 'usage']].value_counts() / len(mask_test))\n",
    "print(valid_mask_test[['type', 'usage']].value_counts() / len(valid_mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image(input_image):\n",
    "    brightness = random.choice([1.0, 0.8, 1.2])\n",
    "    contrast   = random.choice([1.0, 0.8, 1.2])\n",
    "    saturation = random.choice([1.0, 0.8, 1.2])\n",
    "\n",
    "    img_proc = cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)\n",
    "    np.multiply(img_proc, np.array([ 1.0, saturation, 1.0 ], dtype = np.single), out = img_proc)\n",
    "    \n",
    "    img_proc[img_proc > 255] = 255\n",
    "    img_proc[img_proc < 0]   = 0\n",
    "\n",
    "    cv2.cvtColor(img_proc, cv2.COLOR_HSV2RGB, dst = img_proc)\n",
    "    np.multiply(img_proc, brightness, out = img_proc)\n",
    "    np.add(img_proc, ((1-contrast) * 100))\n",
    "\n",
    "    img_proc[img_proc > 255] = 255\n",
    "    img_proc[img_proc < 0]   = 0\n",
    "    img_proc  = img_proc.astype(np.float32) * (1.0 / 255)\n",
    "\n",
    "    return img_proc\n",
    "\n",
    "image_gen  = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range      = 0.1, \n",
    "                                                             height_shift_range     = 0.1, \n",
    "                                                             horizontal_flip        = True,\n",
    "                                                             preprocessing_function = adjust_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_col = 'newFilename'\n",
    "label_cols   = ['type', 'usage']\n",
    "\n",
    "train_ds = image_gen.flow_from_dataframe(mask_train, IMAGE_DIR, \n",
    "                                              x_col       = filename_col, \n",
    "                                              y_col       = label_cols, \n",
    "                                              target_size = IMG_SIZE, \n",
    "                                              class_mode  = 'multi_output',\n",
    "                                              subset      = \"training\", \n",
    "                                              batch_size  = BATCH_SIZE,\n",
    "                                              dtype       = 'float32')\n",
    "\n",
    "test_ds = image_gen.flow_from_dataframe(mask_test, IMAGE_DIR, \n",
    "                                            x_col       = filename_col, \n",
    "                                            y_col       = label_cols, \n",
    "                                            target_size = IMG_SIZE, \n",
    "                                            class_mode  = 'multi_output',\n",
    "                                            batch_size  = BATCH_SIZE,\n",
    "                                            dtype       = 'float32')\n",
    "\n",
    "valid_mask_test_ds = image_gen.flow_from_dataframe(valid_mask_test, IMAGE_DIR, \n",
    "                                            x_col       = filename_col, \n",
    "                                            y_col       = label_cols, \n",
    "                                            target_size = IMG_SIZE, \n",
    "                                            class_mode  = 'multi_output',\n",
    "                                            batch_size  = BATCH_SIZE,\n",
    "                                            dtype       = 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage and Type classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    img   = tf.keras.layers.Input(shape = (128, 128, 3), dtype = 'float32')\n",
    "    base  = tf.keras.applications.ResNet50(include_top = False, input_shape = (*IMG_SIZE,3), pooling = 'max')(img)\n",
    "    base  = tf.keras.layers.Flatten()(base)\n",
    "    base  = tf.keras.layers.Dense(256, activation = 'relu', dtype = 'float32')(base)\n",
    "    t_out = tf.keras.layers.Dense(1, activation = 'sigmoid', dtype = 'float32', name = 'mask_type')(base)\n",
    "    u_out = tf.keras.layers.Dense(1, activation = 'sigmoid', dtype = 'float32', name = 'mask_usage')(base)\n",
    "    model = tf.keras.Model(inputs = img, outputs = [t_out, u_out])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    is_valid = tf.reshape(tf.where(y_true == -1, 0.0, 1.0), (1, -1))\n",
    "    bce_loss = tf.keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    bce_loss = tf.where(is_valid == 1, bce_loss, 0.0)\n",
    "    return tf.reduce_sum(bce_loss) * (1.0 / float(len(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = tf.constant([\n",
    "    [-1.0],\n",
    "    [1.0],\n",
    "    [0.0],\n",
    "    [1.0],\n",
    "])\n",
    "\n",
    "y_pred_test = tf.constant([\n",
    "    [1.0],\n",
    "    [1.0],\n",
    "    [0.0],\n",
    "    [0.0],\n",
    "])\n",
    "\n",
    "# should be zero since they are the same\n",
    "print(custom_loss(y_true_test, y_true_test))\n",
    "\n",
    "# should remain the same even when changing the corresponding y_pred to anything if y_true == -1\n",
    "print(custom_loss(y_true_test, y_pred_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "              loss      = {\n",
    "                  'mask_type' : tf.keras.losses.BinaryCrossentropy(),\n",
    "                  'mask_usage': custom_loss\n",
    "              }, \n",
    "              metrics   = { \n",
    "                  'mask_type'  : [\n",
    "                      'accuracy',\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),\n",
    "                      tf.keras.metrics.TruePositives(),\n",
    "                      tf.keras.metrics.TrueNegatives(),\n",
    "                      tf.keras.metrics.FalsePositives(),\n",
    "                      tf.keras.metrics.FalseNegatives(),\n",
    "                  ]\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data = test_ds, epochs = NUM_EPOCHS, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = model.optimizer, \n",
    "              loss      = model.losses, \n",
    "              metrics   = {\n",
    "                  'mask_usage' : [\n",
    "                      'accuracy',\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),\n",
    "                      tf.keras.metrics.TruePositives(),\n",
    "                      tf.keras.metrics.TrueNegatives(),\n",
    "                      tf.keras.metrics.FalsePositives(),\n",
    "                      tf.keras.metrics.FalseNegatives(),\n",
    "                  ]\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_valid_mask = model.evaluate(valid_mask_test_ds, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved-models/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_mask_test_ds.next()\n",
    "pred = model(x)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27b062b3dfe9606f0c2128da30d74d9d8143ed6a1aa3be014384e6a51e358474"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
